# -*- coding: utf-8 -*-
import os
import time
import gc
import random
import json
import datetime
import re
import sys
import traceback
import itertools
import psutil
from collections import deque

# [í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬]
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
import requests
from bs4 import BeautifulSoup
from dotenv import load_dotenv

import gspread
from oauth2client.service_account import ServiceAccountCredentials

try:
    from google import genai
except ImportError:
    print("âŒ 'google-genai' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. pip install google-genaië¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    sys.exit(1)

load_dotenv()

# ==========================================
# âš™ï¸ [Configuration] ê¸°ì§€ ì¢Œí‘œ ë° ì„¤ì •
# ==========================================

SPREADSHEET_ID = '1lOifE_xRUocAY_Av-P67uBMKOV1BAb4mMwg_wde_tyA'
CREDS_FILE = 'creds_lotto.json'
SHEET_NAME = 'ë¡œë˜ max'
REC_SHEET_NAME = 'ì¶”ì²œë²ˆí˜¸'
LOG_SHEET_NAME = 'ì‘ì „ë¡œê·¸'
STATE_FILE = 'hybrid_sniper_v5_state.pth'
SNIPER_STATE_JSON = 'sniper_state.json'

# ğŸš€ M5 í•˜ë“œì›¨ì–´ ê°€ì† ì„¤ì •
USED_CORES = 6
torch.set_num_threads(USED_CORES)

if torch.backends.mps.is_available():
    DEVICE = torch.device("mps")
    print(f"ğŸš€ [System] M5 Neural Engine (MPS/Metal) ê°€ì† í™œì„±í™”. (Core: {USED_CORES})")
else:
    DEVICE = torch.device("cpu")
    print("âš ï¸ [System] MPS ê°€ì† ë¶ˆê°€. CPU ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")

REAL_BROWSER_HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36",
    "Referer": "https://www.naver.com/"
}

# ==========================================
# ğŸ§  [Core Engine] ì‹ ê²½ë§ ëª¨ë¸ ë° íŠ¹ì§• ì¶”ì¶œ
# ==========================================

class NDA_FeatureEngine:
    """
    [ë°ì´í„° íŠ¹ì§• ê³µí•™ ì—”ì§„]
    ë¡œë˜ ë²ˆí˜¸ì˜ í†µê³„ì  íŠ¹ì§•(í•©ê³„, í™€ì§, ê³ ì €, ACê°’)ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    @staticmethod
    def calculate_derived_features(numbers_list):
        features = []
        for nums in numbers_list:
            if len(nums) < 6:
                features.append([0,0,0,0])
                continue
            s = sum(nums)
            odd = sum(1 for n in nums if n % 2 != 0)
            high = sum(1 for n in nums if n >= 23)
            diffs = set()
            for i in range(len(nums)):
                for j in range(i+1, len(nums)):
                    diffs.add(nums[j] - nums[i])
            ac = len(diffs) - 5
            features.append([s/255.0, odd/6.0, high/6.0, ac/10.0])
        return np.array(features)

    @staticmethod
    def create_multimodal_dataset(data, lookback=10):
        X_seq, X_stat, y = [], [], []
        if len(data) <= lookback: return None, None, None

        raw_nums = np.array(data)
        derived = NDA_FeatureEngine.calculate_derived_features(data)

        for i in range(lookback, len(data)):
            X_seq.append(raw_nums[i-lookback:i] / 45.0)
            X_stat.append(derived[i-1])
            target = np.zeros(45)
            for n in raw_nums[i]: target[n-1] = 1
            y.append(target)

        return (torch.tensor(np.array(X_seq), dtype=torch.float32).to(DEVICE),
                torch.tensor(np.array(X_stat), dtype=torch.float32).to(DEVICE),
                torch.tensor(np.array(y), dtype=torch.float32).to(DEVICE))

class CreativeConnectionModel(nn.Module):
    """
    [í•˜ì´ë¸Œë¦¬ë“œ ì‹ ê²½ë§ ëª¨ë¸]
    LSTM(ì‹œê³„ì—´) + Dense(í†µê³„) ê²°í•© êµ¬ì¡°
    """
    def __init__(self):
        super(CreativeConnectionModel, self).__init__()
        self.lstm = nn.LSTM(input_size=6, hidden_size=128, num_layers=2, batch_first=True, dropout=0.2)
        self.ln_a = nn.LayerNorm(128)
        self.stat_net = nn.Sequential(nn.Linear(4, 32), nn.ReLU(), nn.Linear(32, 32), nn.BatchNorm1d(32))
        self.head = nn.Sequential(nn.Linear(128 + 32, 256), nn.ReLU(), nn.Dropout(0.3), nn.Linear(256, 128), nn.ReLU(), nn.Linear(128, 45), nn.Sigmoid())

    def forward(self, x_seq, x_stat):
        out_seq, _ = self.lstm(x_seq)
        out_seq = self.ln_a(out_seq[:, -1, :])
        out_stat = self.stat_net(x_stat)
        combined = torch.cat([out_seq, out_stat], dim=1)
        return self.head(combined)

# ==========================================
# ğŸ›°ï¸ [System] Orchestrator (Main Logic)
# ==========================================

class SniperState:
    """
    [ì§€ëŠ¥í˜• ìƒíƒœ ê´€ë¦¬ì]
    sniper_state.jsonì„ í†µí•´ ì‘ì „ ìƒíƒœ, í•™ìŠµ ì§€í‘œ, ë™ì  í”„ë¡¬í”„íŠ¸ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
    """
    def __init__(self):
        self.state_file = SNIPER_STATE_JSON
        self.state = self.load_state()

    def load_state(self):
        if os.path.exists(self.state_file):
            try:
                with open(self.state_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except: pass

        # ê¸°ë³¸ ìƒíƒœê°’
        return {
            "last_sync_date": None,
            "last_train_date": None,
            "last_predict_date": None,
            "last_evolution_date": None,
            "last_loss": 0.0,
            "active_strategy_prompt": {
                "version": "v1.0 (Default)",
                "content": """
                ë‹¹ì‹ ì€ ë¡œë˜ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ 50ê°œì˜ ìœ ë ¥ ì¡°í•© ì¤‘, ë‹¹ì²¨ í™•ë¥ ì´ ê°€ì¥ ë†’ì•„ ë³´ì´ëŠ” 5~10ê°œë¥¼ ê³¨ë¼ì£¼ì„¸ìš”.
                ë²ˆí˜¸ê°€ ê³¨ê³ ë£¨ ë¶„í¬ë˜ì–´ ìˆê³ , ë„ˆë¬´ ë»”í•œ íŒ¨í„´ì´ ì•„ë‹Œ ê²ƒì„ ì„ í˜¸í•©ë‹ˆë‹¤.
                """
            },
            "recent_hit_rates": []
        }

    def save_state(self):
        with open(self.state_file, 'w', encoding='utf-8') as f:
            json.dump(self.state, f, ensure_ascii=False, indent=4)

    def update_phase(self, phase_key, value=None):
        if value is None:
            value = datetime.datetime.now().strftime("%Y-%m-%d")
        self.state[phase_key] = value
        self.save_state()

    def update_metric(self, key, value):
        self.state[key] = value
        self.save_state()

    def add_hit_rate(self, hit_rate):
        rates = self.state.get("recent_hit_rates", [])
        rates.append(hit_rate)
        if len(rates) > 5: rates.pop(0)
        self.state["recent_hit_rates"] = rates
        self.save_state()

class LottoOrchestrator:
    def __init__(self):
        self.gc_client = self._auth()
        api_key = os.getenv("GEMINI_API_KEY")
        self.client = self._init_gemini(api_key)
        self.state_manager = SniperState()

        # [ì§€íœ˜ê´€ ëª¨ë¸ ê³ ì •] gemini-2.5-flash
        self.model_name = "gemini-2.5-flash"
        print(f"ğŸ›°ï¸ [System] ì§€íœ˜ê´€ ëª¨ë¸ ì„¤ì •: {self.model_name}")

    def _auth(self):
        """
        [í•˜ì´ë¸Œë¦¬ë“œ ì¸ì¦] ë¡œì»¬ íŒŒì¼ ìš°ì„ , ë¶€ì¬ ì‹œ í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©
        """
        scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive",
                 "https://www.googleapis.com/auth/spreadsheets"]
        try:
            if os.path.exists(CREDS_FILE):
                print("ğŸ”‘ [Auth] ë¡œì»¬ ì¸ì¦ íŒŒì¼ ì‚¬ìš©")
                creds = ServiceAccountCredentials.from_json_keyfile_name(CREDS_FILE, scope)
            elif os.getenv("GOOGLE_CREDS_JSON"):
                print("ğŸ”‘ [Auth] GitHub Secrets ì¸ì¦ ì‚¬ìš©")
                creds_dict = json.loads(os.getenv("GOOGLE_CREDS_JSON"))
                creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
            else:
                raise FileNotFoundError("âŒ ì¸ì¦ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return gspread.authorize(creds)
        except Exception as e:
            print(f"âŒ ì¸ì¦ ì‹¤íŒ¨: {e}")
            sys.exit(1)

    def _init_gemini(self, api_key):
        if not api_key: return None
        try: return genai.Client(api_key=api_key)
        except: return None

    def get_sheet(self):
        try: return self.gc_client.open_by_key(SPREADSHEET_ID)
        except: return self.gc_client.open(SHEET_NAME)

    def cleanup_memory(self):
        """[M5 ìµœì í™”] ë©”ëª¨ë¦¬ ê°•ì œ ì •í™”"""
        gc.collect()
        if torch.backends.mps.is_available():
            torch.mps.empty_cache()

    def log_operation(self, phase, status, detail=""):
        try:
            sh = self.get_sheet()
            try: ws = sh.worksheet(LOG_SHEET_NAME)
            except:
                ws = sh.add_worksheet(title=LOG_SHEET_NAME, rows=1000, cols=10)
                ws.append_row(["Timestamp", "Day", "Phase", "Status", "CPU/MEM", "Detail"])

            now = datetime.datetime.now()
            icon = "âœ…" if status == "SUCCESS" else "âŒ" if status == "FAIL" else "ğŸ’¤"
            ws.insert_row([
                now.strftime("%Y-%m-%d %H:%M:%S"),
                now.strftime("%A"),
                phase,
                f"{icon} {status}",
                f"{psutil.cpu_percent()}% / {psutil.virtual_memory().percent}%",
                detail
            ], 2)
            print(f"ğŸ“ [Log] {phase} - {status}")
        except: pass

    # --- Phase 1: Data Sync ---
    def sync_data(self):
        print("\nğŸ”„ [Phase 1] ë°ì´í„° ë™ê¸°í™” (Naver + Gemini)...")
        self.cleanup_memory()
        try:
            sh = self.get_sheet()
            ws = sh.get_worksheet(0)
            col1 = ws.col_values(1)
            rounds = [int(str(v).replace('íšŒ','').replace(',','').strip()) for v in col1 if str(v).replace('íšŒ','').replace(',','').strip().isdigit()]
            local_last = max(rounds) if rounds else 0
            portal_last = self._get_naver_latest_round()
            print(f"   ğŸ“Š ìƒíƒœ: ë¡œì»¬({local_last}) vs ë„¤ì´ë²„({portal_last})")

            cnt = 0
            if portal_last > local_last:
                for r in range(local_last + 1, portal_last + 1):
                    data = self._scrape_round_detail(r)
                    if data:
                        row = [data['drwNo'], data['drwNoDate'], data['drwtNo1'], data['drwtNo2'], data['drwtNo3'],
                               data['drwtNo4'], data['drwtNo5'], data['drwtNo6'], data['bnusNo'],
                               data.get('firstPrzwnerCo', 0), data.get('firstAccumamnt', 0), ""]
                        ws.insert_row(row, 2)
                        cnt += 1
                        time.sleep(2)
            else:
                print("   âœ… ìµœì‹  ìƒíƒœì„.")

            self.state_manager.update_phase("last_sync_date")
            self.log_operation("Phase 1", "SUCCESS", f"Updated {cnt}")
        except Exception as e:
            print(f"âŒ ë™ê¸°í™” ì‹¤íŒ¨: {e}")
            self.log_operation("Phase 1", "FAIL", str(e))
        finally:
            self.cleanup_memory()

    def _get_naver_latest_round(self):
        try:
            res = requests.get("https://search.naver.com/search.naver?query=ë¡œë˜", headers=REAL_BROWSER_HEADERS, timeout=5)
            m = re.search(r'(\d+)íšŒì°¨', res.text)
            return int(m.group(1)) if m else 0
        except: return 0

    def _scrape_round_detail(self, round_no):
        url = f"https://search.naver.com/search.naver?query=ë¡œë˜+{round_no}íšŒ+ë‹¹ì²¨ë²ˆí˜¸"
        try:
            res = requests.get(url, headers=REAL_BROWSER_HEADERS, timeout=5)
            soup = BeautifulSoup(res.text, 'html.parser')
            text = soup.get_text()[:3000]
            if self.client:
                prompt = f"JSON for Lotto {round_no} from: {text}"
                try:
                    resp = self.client.models.generate_content(model=self.model_name, contents=prompt)
                    return json.loads(resp.text.strip().replace('```json','').replace('```',''))
                except: pass

            # Fallback
            nums = re.findall(r'\b(\d{1,2})\b', text)
            valid = [int(n) for n in nums if 1 <= int(n) <= 45]
            if len(valid) >= 7:
                return {"drwNo": round_no, "drwNoDate": datetime.datetime.now().strftime("%Y-%m-%d"),
                        "drwtNo1": valid[0], "drwtNo2": valid[1], "drwtNo3": valid[2],
                        "drwtNo4": valid[3], "drwtNo5": valid[4], "drwtNo6": valid[5], "bnusNo": valid[6]}
            return None
        except: return None

    # --- Phase 2: Train ---
    def load_data(self):
        try:
            sh = self.get_sheet()
            ws = sh.get_worksheet(0)
            rows = ws.get_all_values()[1:]
            data = []
            for r in rows:
                try:
                    nums = [int(str(x).replace(',', '')) for x in r[2:8]]
                    data.append(nums)
                except: pass
            data.reverse()
            return data
        except: return []

    def train_brain(self):
        print("\nğŸ§  [Phase 2] ëª¨ë¸ í•™ìŠµ (M5)...")
        self.cleanup_memory()
        try:
            data = self.load_data()
            if len(data) < 50: return

            X_seq, X_stat, y = NDA_FeatureEngine.create_multimodal_dataset(data, 10)
            model = CreativeConnectionModel().to(DEVICE)
            opt = optim.Adam(model.parameters(), lr=0.001)
            crit = nn.BCELoss()

            model.train()
            loss_val = 0
            for e in range(100):
                opt.zero_grad()
                loss = crit(model(X_seq, X_stat), y)
                loss.backward()
                opt.step()
                loss_val = loss.item()
                if (e+1)%20 == 0: print(f"   Epoch {e+1}: {loss_val:.4f}")

            torch.save(model.state_dict(), STATE_FILE)
            self.state_manager.update_phase("last_train_date")
            self.state_manager.update_metric("last_loss", loss_val)
            self.log_operation("Phase 2", "SUCCESS", f"Loss: {loss_val:.4f}")
            del model, X_seq, X_stat, y
        except Exception as e:
            self.log_operation("Phase 2", "FAIL", str(e))
        finally:
            self.cleanup_memory()

    # --- Phase 3: Predict ---
    def load_and_predict(self):
        print("\nğŸ”® [Phase 3] ì§€ëŠ¥í˜• ì˜ˆì¸¡ (ë™ì  í”„ë¡¬í”„íŠ¸)...")
        self.cleanup_memory()
        try:
            data = self.load_data()
            if not data or not os.path.exists(STATE_FILE): return

            model = CreativeConnectionModel().to(DEVICE)
            model.load_state_dict(torch.load(STATE_FILE, map_location=DEVICE))
            model.eval()

            # 1. Top 20 Extraction
            last_seq = data[-10:]
            input_seq = torch.tensor(np.array(last_seq)/45.0, dtype=torch.float32).unsqueeze(0).to(DEVICE)
            input_stat = torch.tensor(NDA_FeatureEngine.calculate_derived_features([data[-1]]), dtype=torch.float32).to(DEVICE)

            with torch.no_grad():
                probs = model(input_seq, input_stat).cpu().numpy()[0]

            top_20 = [int(n+1) for n in probs.argsort()[::-1][:20]]
            print(f"   ğŸ¯ Top 20: {sorted(top_20)}")

            # 2. Simulation & Filtering
            combos = list(itertools.combinations(top_20, 6))
            if len(combos) > 10000: combos = random.sample(combos, 10000)

            filtered = []
            for c in combos:
                if 100 <= sum(c) <= 170 and 2 <= sum(1 for n in c if n%2!=0) <= 4:
                    filtered.append(sorted(list(c)))

            candidates = random.sample(filtered, 50) if len(filtered) > 50 else filtered
            print(f"   âœ… í›„ë³´ ì••ì¶•: {len(candidates)}ê°œ")

            # 3. LLM Selection (Dynamic Prompt)
            final = self._ask_gemini(candidates)
            self._write_sheet(final if final else candidates[:10])

            self.state_manager.update_phase("last_predict_date")
            self.log_operation("Phase 3", "SUCCESS", f"Generated {len(final) if final else 10}")

        except Exception as e:
            print(f"âŒ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            self.log_operation("Phase 3", "FAIL", str(e))
        finally:
            self.cleanup_memory()

    def _ask_gemini(self, candidates):
        if not self.client: return None

        # [ë™ì  í”„ë¡¬í”„íŠ¸ ë¡œë“œ]
        state_prompt = self.state_manager.state.get("active_strategy_prompt", {})
        prompt_content = state_prompt.get("content", "ê¸°ë³¸ í”„ë¡¬í”„íŠ¸: ê³¨ê³ ë£¨ ë¶„í¬ëœ ë²ˆí˜¸ë¥¼ ê³ ë¥´ì„¸ìš”.")
        version = state_prompt.get("version", "Default")

        print(f"   ğŸ§¬ ì ìš©ëœ ì „ëµ: {version}")

        c_str = "\n".join([f"{i+1}. {c}" for i, c in enumerate(candidates)])
        full_prompt = f"{prompt_content}\n\n[í›„ë³´]\n{c_str}\n\n[ì¶œë ¥]\nì˜¤ì§ JSON ë°°ì—´ë§Œ ì¶œë ¥."

        try:
            resp = self.client.models.generate_content(model=self.model_name, contents=full_prompt)
            return json.loads(resp.text.strip().replace('```json','').replace('```',''))
        except: return None

    def _write_sheet(self, games):
        try:
            sh = self.get_sheet()
            try: ws = sh.worksheet(REC_SHEET_NAME)
            except: ws = sh.add_worksheet(REC_SHEET_NAME, 100, 20)
            ws.clear()
            ws.update(range_name='A1', values=[['ğŸ† Sniper V5 ì¶”ì²œ ë²ˆí˜¸']])
            ws.update(range_name='A3', values=[[f"ì‹œë‚˜ë¦¬ì˜¤ {i+1}"] + g for i, g in enumerate(games)])
            print("   âœ… ì‹œíŠ¸ ì €ì¥ ì™„ë£Œ.")
        except: pass

    # --- Phase 4: Evaluate ---
    def evaluate_performance(self):
        print("\nğŸ… [Phase 4] ì„±ê³¼ í‰ê°€...")
        try:
            sh = self.get_sheet()
            main_ws = sh.get_worksheet(0)
            row = main_ws.row_values(2)
            real = set([int(x) for x in row[2:8]])
            bonus = int(row[8])

            try: rec_ws = sh.worksheet(REC_SHEET_NAME)
            except: return

            preds = []
            for r in rec_ws.get_all_values():
                if "ì‹œë‚˜ë¦¬ì˜¤" in r[0]:
                    preds.append(set([int(x) for x in r[1:7] if x]))

            if not preds: return

            total_hits = 0
            max_hit = 0
            for p in preds:
                cnt = len(real.intersection(p))
                total_hits += cnt
                if cnt > max_hit: max_hit = cnt

            avg = total_hits / len(preds)
            self.state_manager.add_hit_rate(avg)
            self.log_operation("Phase 4", "SUCCESS", f"Max: {max_hit}, Avg: {avg:.2f}")
            print(f"   ğŸ“Š ê²°ê³¼: ìµœê³  {max_hit}ê°œ, í‰ê·  {avg:.2f}ê°œ")

        except Exception as e:
            self.log_operation("Phase 4", "FAIL", str(e))

if __name__ == "__main__":
    app = LottoOrchestrator()
    print("ğŸš€ Manual Run...")
    app.sync_data()
    app.train_brain()
    app.load_and_predict()
    # app.evaluate_performance()
