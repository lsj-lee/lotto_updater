import gspread
from google.oauth2.service_account import Credentials
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import time
import datetime
import random
import os
from google import genai
import json
from dotenv import load_dotenv

# ==========================================
# [1] í™˜ê²½ ì„¤ì • ë° ì¥ì¹˜ í™•ì¸
# ==========================================
# .env íŒŒì¼ ë¡œë“œ
load_dotenv()
print(f"DEBUG: ë¡œë“œëœ í‚¤1: {os.getenv('GEMINI_API_KEY_1')[:10]}...")

# M5 ì¹©(Apple Silicon) ê°€ì† ëª¨ë“œ í™•ì¸
device = torch.device("mps") if torch.backends.mps.is_available() else torch.device("cpu")
print(f"ğŸš€ í•™ìŠµ ì¥ì¹˜ ì„¤ì •: {device} (MacBook Pro M5 ê°€ì† ëª¨ë“œ)")

# êµ¬ê¸€ ì„œë¹„ìŠ¤ ê³„ì • í‚¤ ê²½ë¡œ
KEY_PATH = "/Users/lsj/Desktop/êµ¬ê¸€ ì—°ê²° í‚¤/creds lotto.json"

# ì œë¯¸ë‚˜ì´ API í‚¤ ë¡œë“œ (ë©€í‹° í‚¤ ë¡œí…Œì´ì…˜)
GEMINI_API_KEY_1 = os.getenv("GEMINI_API_KEY_1")
GEMINI_API_KEY_2 = os.getenv("GEMINI_API_KEY_2")

API_KEYS = [key for key in [GEMINI_API_KEY_1, GEMINI_API_KEY_2] if key]

if API_KEYS:
    print(f"âœ… ì œë¯¸ë‚˜ì´ API í‚¤ê°€ {len(API_KEYS)}ê°œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
else:
    print("âš ï¸ GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# í•™ìŠµ ì‹œì•¼(Window Size) ì„¤ì • - 8ê°€ì§€ ê´€ì 
SCALES = [10, 50, 100, 200, 300, 500, 700, 1000]

# ==========================================
# [2] í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ì •ì˜ (Tabular-Insight V5)
# ==========================================

# 2-1. [TabNet ì‘ìš©] Feature-Attention Layer
# ì…ë ¥ íŠ¹ì§•(Feature) ê°„ì˜ ì¤‘ìš”ë„ë¥¼ í•™ìŠµí•˜ì—¬ ë¹„ì„ í˜• ìƒí˜¸ì‘ìš©ì„ í¬ì°©í•©ë‹ˆë‹¤.
class TabularFeatureAttention(nn.Module):
    def __init__(self, input_dim):
        super(TabularFeatureAttention, self).__init__()
        # ê° íŠ¹ì§•ì— ëŒ€í•œ ê°€ì¤‘ì¹˜ ë§ˆìŠ¤í¬ í•™ìŠµ (0~1 ì‚¬ì´ ê°’)
        self.mask = nn.Sequential(
            nn.Linear(input_dim, input_dim),
            nn.Sigmoid()
        )

    def forward(self, x):
        # x: (batch, seq_len, input_dim)
        # ë§ˆìŠ¤í¬ ìƒì„±: (batch, seq_len, input_dim)
        mask_val = self.mask(x)
        # ì…ë ¥ ê°’ì— ì¤‘ìš”ë„(mask)ë¥¼ ê³±í•˜ì—¬ ì¤‘ìš”í•œ íŠ¹ì§•ì„ ê°•ì¡°
        return x * mask_val

# 2-2. ê¸°ì¡´ LSTM + Self-Attention êµ¬ì¡°ì— Feature-Attention ì¶”ê°€
class SelfAttention(nn.Module):
    def __init__(self, hidden_size):
        super(SelfAttention, self).__init__()
        self.hidden_size = hidden_size
        self.projection = nn.Sequential(
            nn.Linear(hidden_size, 64),
            nn.ReLU(True),
            nn.Linear(64, 1)
        )

    def forward(self, encoder_outputs):
        # encoder_outputs: (batch, seq_len, hidden_size)
        energy = self.projection(encoder_outputs) # (batch, seq_len, 1)
        weights = torch.softmax(energy.squeeze(-1), dim=1) # (batch, seq_len)
        # (batch, 1, seq_len) * (batch, seq_len, hidden_size) -> (batch, 1, hidden_size)
        outputs = (encoder_outputs * weights.unsqueeze(-1)).sum(dim=1)
        return outputs, weights

class LottoBrain(nn.Module):
    def __init__(self, input_size=12, hidden_size=128, num_layers=3, output_size=12):
        super(LottoBrain, self).__init__()
        # [V5 Upgrade] Tabular Feature Attention ë„ì…
        self.feature_attention = TabularFeatureAttention(input_size)

        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.attention = SelfAttention(hidden_size)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        # 1. Feature Attention ì ìš© (TabNet ê°œë…)
        x = self.feature_attention(x)

        # 2. LSTM
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)
        lstm_out, _ = self.lstm(x, (h0, c0)) # (batch, seq_len, hidden_size)

        # 3. Temporal Self-Attention
        attn_out, _ = self.attention(lstm_out) # (batch, hidden_size)

        # 4. Final Prediction
        out = self.fc(attn_out)
        return out

# 2-3. [cGAN ì‘ìš©] ë°ì´í„° ì¦ê°•ìš© ìƒì„±ì  ì ëŒ€ ì‹ ê²½ë§
# ê³¼ê±° ë‹¹ì²¨ íŒ¨í„´ì„ í•™ìŠµí•˜ì—¬ "ë‹¹ì²¨ ê°€ëŠ¥ì„±ì´ ë†’ì€ ê°€ìƒì˜ 10ë§Œ ê°œ ì¡°í•©"ì„ ìƒì„±í•©ë‹ˆë‹¤.
class LottoGenerator(nn.Module):
    def __init__(self, z_dim=16, output_dim=45):
        super(LottoGenerator, self).__init__()
        self.net = nn.Sequential(
            nn.Linear(z_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 128),
            nn.ReLU(),
            nn.Linear(128, output_dim),
            nn.Sigmoid() # 1~45ë²ˆ ë²ˆí˜¸ë³„ í™•ë¥  ì¶œë ¥ (Multi-label)
        )

    def forward(self, z):
        return self.net(z)

class LottoDiscriminator(nn.Module):
    def __init__(self, input_dim=45):
        super(LottoDiscriminator, self).__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.LeakyReLU(0.2),
            nn.Linear(128, 64),
            nn.LeakyReLU(0.2),
            nn.Linear(64, 1),
            nn.Sigmoid() # Real(1) or Fake(0)
        )

    def forward(self, x):
        return self.net(x)

# ==========================================
# [3] ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
# ==========================================
def connect_jules():
    """êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ê°ì²´ ë°˜í™˜"""
    scopes = [
        'https://www.googleapis.com/auth/spreadsheets',
        'https://www.googleapis.com/auth/drive'
    ]
    try:
        if not os.path.exists(KEY_PATH):
            print(f"âŒ ì¸ì¦ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {KEY_PATH}")
            return None

        creds = Credentials.from_service_account_file(KEY_PATH, scopes=scopes)
        client = gspread.authorize(creds)
        spreadsheet = client.open("ë¡œë˜ max") 
        return spreadsheet
    except Exception as e:
        print(f"âŒ ì¤„ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

def calculate_advanced_features(df):
    """
    ê¸°ì¡´ 9ê°œ ì»¬ëŸ¼ì— ì¶”ê°€ 3ê°œ ì»¬ëŸ¼(Gap Analysis, Odd/Even, Sum)ì„ ìƒì„±í•˜ì—¬ ë°˜í™˜
    """
    number_cols = ['1ë²ˆ', '2ë²ˆ', '3ë²ˆ', '4ë²ˆ', '5ë²ˆ', '6ë²ˆ']

    gaps_list = []
    odd_even_list = []
    sum_list = []

    last_seen = {i: -1 for i in range(1, 46)}

    for idx, row in df.iterrows():
        current_nums = [int(row[col]) for col in number_cols]

        # 1. Sum
        current_sum = sum(current_nums)
        sum_list.append(current_sum)

        # 2. Odd/Even Ratio
        odd_count = sum(1 for n in current_nums if n % 2 != 0)
        odd_even_ratio = odd_count / 6.0
        odd_even_list.append(odd_even_ratio)

        # 3. Gap Analysis
        current_gaps = []
        for n in current_nums:
            if last_seen[n] == -1:
                gap = idx
            else:
                gap = idx - last_seen[n]
            current_gaps.append(gap)
            last_seen[n] = idx

        avg_gap = sum(current_gaps) / 6.0
        gaps_list.append(avg_gap)

    df['Average_Gap'] = gaps_list
    df['Odd_Even_Ratio'] = odd_even_list
    df['Sum'] = sum_list

    return df

def load_data():
    """'ì‹œíŠ¸1'ì—ì„œ ë¡œë˜ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
    sheet = connect_jules()
    if not sheet: return None

    try:
        ws = sheet.worksheet("ì‹œíŠ¸1")
        data = ws.get_all_values()
        df = pd.DataFrame(data[1:], columns=data[0])

        # ì „ì²˜ë¦¬
        df['ë‹¹ì²¨ì ìˆ˜'] = df['ë‹¹ì²¨ì ìˆ˜'].astype(str).str.replace('ëª…', '').str.replace(',', '').astype(float)
        df['1ê²Œì„ë‹¹ ì´ ë‹¹ì²¨ê¸ˆì•¡'] = df['1ê²Œì„ë‹¹ ì´ ë‹¹ì²¨ê¸ˆì•¡'].astype(str).str.replace('ì›', '').str.replace(',', '').astype(float)

        cols = ['1ë²ˆ', '2ë²ˆ', '3ë²ˆ', '4ë²ˆ', '5ë²ˆ', '6ë²ˆ', 'ë³´ë„ˆìŠ¤', 'ë‹¹ì²¨ì ìˆ˜', '1ê²Œì„ë‹¹ ì´ ë‹¹ì²¨ê¸ˆì•¡']
        df = df[cols].apply(pd.to_numeric)

        # LSTM í•™ìŠµìš© (ê³¼ê±° -> ìµœì‹ )
        df_reversed = df.iloc[::-1].reset_index(drop=True)

        # íŠ¹ì„± ê³µí•™ ì¶”ê°€
        df_enhanced = calculate_advanced_features(df_reversed)

        return df_enhanced
    except Exception as e:
        print(f"âš ï¸ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

# ==========================================
# [4] AI ììœ¨ í•™ìŠµ ë° ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸
# ==========================================

# 4-1. cGAN í•™ìŠµ ë° ê°€ìƒ ë°ì´í„° ìƒì„± í•¨ìˆ˜
def train_cgan_and_generate(df, epochs=500, samples=100000):
    """
    cGANì„ í•™ìŠµí•˜ê³  10ë§Œ ê°œì˜ ê°€ìƒ ë‹¹ì²¨ ë²ˆí˜¸ë¥¼ ìƒì„±í•˜ì—¬
    ê° ë²ˆí˜¸ì˜ ì¶œí˜„ í™•ë¥ (ê°€ì¤‘ì¹˜)ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    print("\nâš¡ [cGAN Data Augmentation] ê°€ìƒ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘...")

    # ì‹¤ì œ ë‹¹ì²¨ ë²ˆí˜¸ ë°ì´í„° ì¤€ë¹„ (One-hot encodingê³¼ ìœ ì‚¬í•˜ê²Œ 45ì°¨ì› ë²¡í„°í™”)
    real_data = []
    number_cols = ['1ë²ˆ', '2ë²ˆ', '3ë²ˆ', '4ë²ˆ', '5ë²ˆ', '6ë²ˆ']

    for _, row in df.iterrows():
        vec = np.zeros(45)
        for col in number_cols:
            idx = int(row[col]) - 1 # 0-indexed
            if 0 <= idx < 45:
                vec[idx] = 1.0
        real_data.append(vec)

    real_tensor = torch.tensor(np.array(real_data), dtype=torch.float32).to(device)

    # ëª¨ë¸ ì´ˆê¸°í™”
    z_dim = 16
    generator = LottoGenerator(z_dim=z_dim).to(device)
    discriminator = LottoDiscriminator().to(device)

    g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)
    d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)
    criterion = nn.BCELoss()

    # í•™ìŠµ ë£¨í”„ (ê°„ì†Œí™”ë¨)
    start_time = time.time()
    batch_size = 64

    for epoch in range(epochs):
        # 1. Discriminator í•™ìŠµ
        idx = np.random.randint(0, real_tensor.size(0), batch_size)
        real_batch = real_tensor[idx]

        # Real Labels
        real_labels = torch.ones(batch_size, 1).to(device)
        fake_labels = torch.zeros(batch_size, 1).to(device)

        # Train Real
        d_optimizer.zero_grad()
        outputs = discriminator(real_batch)
        d_loss_real = criterion(outputs, real_labels)

        # Train Fake
        z = torch.randn(batch_size, z_dim).to(device)
        fake_batch = generator(z)
        outputs = discriminator(fake_batch.detach())
        d_loss_fake = criterion(outputs, fake_labels)

        d_loss = d_loss_real + d_loss_fake
        d_loss.backward()
        d_optimizer.step()

        # 2. Generator í•™ìŠµ
        g_optimizer.zero_grad()
        z = torch.randn(batch_size, z_dim).to(device)
        fake_batch = generator(z)
        outputs = discriminator(fake_batch)

        # GeneratorëŠ” Discriminatorë¥¼ ì†ì—¬ì•¼ í•¨ (Label=1)
        g_loss = criterion(outputs, real_labels)
        g_loss.backward()
        g_optimizer.step()

    print(f"  â””â”€ cGAN í•™ìŠµ ì™„ë£Œ ({epochs} epochs, {time.time()-start_time:.2f}s)")

    # 10ë§Œ ê°œ ê°€ìƒ ìƒ˜í”Œ ìƒì„±
    generator.eval()
    with torch.no_grad():
        z_large = torch.randn(samples, z_dim).to(device)
        generated_data = generator(z_large).cpu().numpy() # (100000, 45) í™•ë¥ ê°’

    # ê° ë²ˆí˜¸ë³„ í‰ê·  í™•ë¥  ê³„ì‚° (ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš©)
    # generated_dataëŠ” ê° ë²ˆí˜¸ê°€ ë‚˜ì˜¬ í™•ë¥ (0~1)ì„ ë‚˜íƒ€ëƒ„
    # ì „ì²´ ìƒ˜í”Œì— ëŒ€í•´ í‰ê· ì„ ë‚´ë©´, cGANì´ ì˜ˆì¸¡í•˜ëŠ” í•´ë‹¹ ë²ˆí˜¸ì˜ "ë‹¹ì²¨ ê°€ëŠ¥ì„±"ì´ ë¨
    cgan_weights = np.mean(generated_data, axis=0) # (45,)

    # ì •ê·œí™” (ìµœëŒ€ê°’ 1.0)
    cgan_weights = cgan_weights / np.max(cgan_weights)

    # 1-indexed ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
    cgan_weight_dict = {i+1: float(cgan_weights[i]) for i in range(45)}
    print(f"  â””â”€ 10ë§Œ ê°œ ê°€ìƒ ì¡°í•© ìƒì„± ë° íŒ¨í„´ ë¶„ì„ ì™„ë£Œ.")

    return cgan_weight_dict

# 4-2. LSTM í•™ìŠµ í•¨ìˆ˜
def train_model(X, y, epochs=1000):
    model = LottoBrain(12, 128, 3, 12).to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.MSELoss()

    model.train()
    for epoch in range(epochs):
        optimizer.zero_grad()
        loss = criterion(model(X), y)
        loss.backward()
        optimizer.step()
    return model

# 4-3. í†µí•© íŒŒì´í”„ë¼ì¸
def run_pipeline(df):
    """
    1. cGAN ë°ì´í„° ì¦ê°• ë° íŒ¨í„´ í•™ìŠµ
    2. LSTM-Attention 8ë‹¨ê³„ ì‹œì•¼ í•™ìŠµ
    3. PPO ê°œë…ì˜ ë™ì  ê°€ì¤‘ì¹˜(Dynamic Weighting) ì ìš©
    """
    print("\n" + "="*50)
    print("ğŸ§  [Hybrid Sniper V5: Tabular-Insight] ì—”ì§„ ê°€ë™")
    print("="*50)

    # (1) cGAN ê¸°ë°˜ ê°€ì¤‘ì¹˜ ìƒì„±
    cgan_weights = train_cgan_and_generate(df)

    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(df.values)

    results = [] # (prediction_nums, weight)

    for seq_len in SCALES:
        if len(scaled_data) <= seq_len + 5: continue

        print(f"\nğŸ”­ [{seq_len}ì£¼ ì‹œì•¼] Tabular-Attention ë¶„ì„ ë° PPO ìµœì í™”...")

        # (2) Dynamic Weighting (PPO ê°œë…: Reward ê¸°ë°˜ Policy ì—…ë°ì´íŠ¸)
        val_size = 5
        train_data_len = len(scaled_data) - val_size

        X_val_train = []
        y_val_train = []
        for i in range(seq_len, train_data_len):
            X_val_train.append(scaled_data[i-seq_len:i])
            y_val_train.append(scaled_data[i])

        X_val_tensor = torch.tensor(np.array(X_val_train), dtype=torch.float32).to(device)
        y_val_tensor = torch.tensor(np.array(y_val_train), dtype=torch.float32).to(device)

        # ê²€ì¦ìš© ëª¨ë¸ í•™ìŠµ
        val_model = train_model(X_val_tensor, y_val_tensor, epochs=300)

        # ìµœê·¼ 5íšŒì°¨ ì˜ˆì¸¡ ë° ë³´ìƒ(Reward) ê³„ì‚°
        val_score = 0
        val_model.eval()
        with torch.no_grad():
            for k in range(val_size):
                idx = train_data_len + k
                input_seq = scaled_data[idx-seq_len:idx]
                input_tensor = torch.tensor(input_seq, dtype=torch.float32).unsqueeze(0).to(device)

                pred_scaled = val_model(input_tensor).cpu().numpy()
                pred_original = scaler.inverse_transform(pred_scaled)
                actual_original = scaler.inverse_transform(scaled_data[idx].reshape(1, -1))

                pred_nums = set(np.round(pred_original[0][:6]).astype(int))
                actual_nums = set(np.round(actual_original[0][:6]).astype(int))

                match_cnt = len(pred_nums.intersection(actual_nums))
                val_score += match_cnt

        # PPO Policy: ë³´ìƒì´ ë†’ì„ìˆ˜ë¡ í•´ë‹¹ ëª¨ë¸(Policy)ì˜ ê°€ì¤‘ì¹˜ë¥¼ ë†’ì„
        model_weight = 1.0 + (val_score * 0.5)
        print(f"  â””â”€ âš–ï¸ Policy Weight: {model_weight:.2f} (Reward: {val_score})")

        # (3) ë³¸ í•™ìŠµ
        print(f"  â””â”€ ğŸš€ ì „ì²´ ë°ì´í„° ì‹¤ì „ í•™ìŠµ ì¤‘...")
        X_full, y_full = [], []
        for i in range(seq_len, len(scaled_data)):
            X_full.append(scaled_data[i-seq_len:i])
            y_full.append(scaled_data[i])

        X_full_tensor = torch.tensor(np.array(X_full), dtype=torch.float32).to(device)
        y_full_tensor = torch.tensor(np.array(y_full), dtype=torch.float32).to(device)

        final_model = train_model(X_full_tensor, y_full_tensor, epochs=500 if seq_len < 500 else 300)

        # (4) ë¯¸ë˜ ì˜ˆì¸¡
        final_model.eval()
        with torch.no_grad():
            last_seq = scaled_data[-seq_len:]
            last_seq_tensor = torch.tensor(last_seq, dtype=torch.float32).unsqueeze(0).to(device)
            predicted_scaled = final_model(last_seq_tensor).cpu().numpy()
            predicted_original = scaler.inverse_transform(predicted_scaled)

            lotto_nums = np.round(predicted_original[0][:6]).astype(int)
            lotto_nums = np.clip(lotto_nums, 1, 45)
            unique_nums = np.unique(lotto_nums)

            if len(unique_nums) < 6:
                missing = 6 - len(unique_nums)
                avail = list(set(range(1, 46)) - set(unique_nums))
                filled = random.sample(avail, missing)
                final_nums = sorted(list(unique_nums) + filled)
            else:
                final_nums = sorted(list(unique_nums))

            final_nums = [int(n) for n in final_nums]
            results.append({'nums': final_nums, 'weight': model_weight})

    return results, cgan_weights

# ==========================================
# [5] ì œë¯¸ë‚˜ì´ AI ì „ëµê°€ (Hyper-Sniper V5 Mode)
# ==========================================
def get_gemini_strategy(scores):
    if not API_KEYS:
        print("âš ï¸ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
        return None

    models = [
        'gemini-3-flash-preview',
        'gemini-2.5-flash',
        'gemini-flash-latest'
    ]

    prompt = f"""
    ë„ˆëŠ” ìµœê³ ì˜ ë¡œë˜ ì „ëµê°€ì´ì ìµœì²¨ë‹¨ AI ì—°êµ¬ì›ì´ì•¼.
    ì´ë²ˆ ì£¼ëŠ” **'Hybrid Sniper V5: Tabular-Insight Edition'** ëª¨ë“œë¡œ ì‘ë™í•œë‹¤.

    [ì‹œìŠ¤í…œ ì—…ê·¸ë ˆì´ë“œ ë‚´ì—­]
    1. **Tabular Feature Attention (TabNet ê¸°ë°˜):** ë²ˆí˜¸ ê°„ì˜ ë¹„ì„ í˜• ìƒí˜¸ì‘ìš©ì„ í¬ì°©í•˜ì—¬ LSTM ì…ë ¥ ì „ì²˜ë¦¬ ê°•í™”.
    2. **cGAN Data Augmentation:** ê³¼ê±° íŒ¨í„´ì„ í•™ìŠµí•œ ìƒì„±ì  ì ëŒ€ ì‹ ê²½ë§ì´ 10ë§Œ ê°œì˜ ê°€ìƒ ë‹¹ì²¨ ì¡°í•©ì„ ìƒì„±í•˜ì—¬ í•„í„°ë§ ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš©.
    3. **PPO (Proximal Policy Optimization) Inspired:** ìµœê·¼ 5ì£¼ ì„±ê³¼(Reward)ì— ë”°ë¼ ëª¨ë¸ë³„ ê°€ì¤‘ì¹˜(Policy)ë¥¼ ë™ì ìœ¼ë¡œ ìµœì í™”.

    ì•„ë˜ ë°ì´í„°ëŠ” ìœ„ ê¸°ìˆ ë“¤ì´ ì ìš©ëœ ìµœì¢… ë²ˆí˜¸ë³„ í™•ë¥  ì ìˆ˜ì•¼.

    [í™•ë¥  ë°ì´í„° (Top 45)]
    {json.dumps(scores)}

    [ë„ˆì˜ ì„ë¬´]
    1. ì „ì²´ 45ê°œ ë²ˆí˜¸ ì¤‘ ì´ë²ˆ ì£¼ ë‹¹ì²¨ í™•ë¥ ì´ ê°€ì¥ ê°•ë ¥í•œ **'ì •ì˜ˆ ë²ˆí˜¸ 15~20ê°œ'**ë¥¼ ì—„ì„ í•˜ë¼.
    2. ì—„ì„ ëœ ì •ì˜ˆ ë²ˆí˜¸ *ë§Œì„* ì‚¬ìš©í•˜ì—¬ ìˆ˜í•™ì ìœ¼ë¡œ ê°€ì¥ ë‹¹ì²¨ í™•ë¥ ì´ ë†’ì€ **'ìµœì¢… 10ê²Œì„'**ì„ êµ¬ì„±í•˜ë¼.
    3. **R&D Insight ì„¹ì…˜ ì‘ì„±:**
       - ì´ë²ˆì— ì ìš©ëœ **TabNet, cGAN, PPO** ê¸°ìˆ ì´ ì‹¤ì œ ë¡œë˜ ì˜ˆì¸¡ì— ì–´ë–»ê²Œ ê¸°ì—¬í–ˆëŠ”ì§€, í˜¹ì€ í–¥í›„ ì–´ë–»ê²Œ ë°œì „ì‹œí‚¬ ìˆ˜ ìˆì„ì§€ ì—°êµ¬ì› ê´€ì ì—ì„œ 3ì¤„ ìš”ì•½í•´ì¤˜.

    [ì¶œë ¥ í˜•ì‹]
    ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•´. ì„¤ëª…ì´ë‚˜ ë§ˆí¬ë‹¤ìš´ ì—†ì´ ìˆœìˆ˜ JSONë§Œ.
    {{
        "strategy_summary": "ì „ëµ ìš”ì•½ í…ìŠ¤íŠ¸ (í•œê¸€ 3ë¬¸ì¥ ì´ë‚´)",
        "elite_numbers": [1, 5, 10, ...],
        "final_10_games": [[1, 2, 3, 4, 5, 6], ... (ì´ 10ê°œ)],
        "rd_insight": "R&D ì œì•ˆ ë‚´ìš© (TabNet, cGAN, PPO ì–¸ê¸‰ í•„ìˆ˜)"
    }}
    """

    print("\nğŸ¤– [Gemini AI] 'Hyper-Sniper V5' ì „ëµ ìˆ˜ë¦½ ë° R&D ë¶„ì„ ì¤‘...")

    for model_idx, model_name in enumerate(models):
        print(f"ğŸ” [{model_idx + 1}ë‹¨ê³„] {model_name} ì‹œë„ ì¤‘...")

        for i, key in enumerate(API_KEYS):
            try:
                client = genai.Client(api_key=key)
                response = client.models.generate_content(
                    model=model_name,
                    contents=prompt
                )

                text_content = response.text
                if "```json" in text_content:
                    text_content = text_content.split("```json")[1].split("```")[0].strip()
                elif "```" in text_content:
                    text_content = text_content.split("```")[1].split("```")[0].strip()

                result = json.loads(text_content)

                if "final_10_games" in result and len(result["final_10_games"]) > 0:
                    print(f"âœ¨ [ìµœì¢… ìŠ¹ì¸] '{model_name}' ì—”ì§„ì´ ì „ëµì„ í™•ì •í–ˆìŠµë‹ˆë‹¤.")
                    return result

            except Exception as e:
                error_msg = str(e)
                if "429" in error_msg or "Quota exceeded" in error_msg:
                    break

                print(f"âŒ Key {i+1} í˜¸ì¶œ ì‹¤íŒ¨ ({model_name}): {error_msg}")
                if i < len(API_KEYS) - 1:
                    time.sleep(2) # ì§§ì€ ëŒ€ê¸°

    print("âš ï¸ ëª¨ë“  ëª¨ë¸ ë° API í‚¤ ì‹œë„ ì‹¤íŒ¨.")
    return None

# ==========================================
# [6] AI ììœ¨ í•„í„°ë§ ë° ê²Œì„ ìƒì„±
# ==========================================
def analyze_and_generate(results, cgan_weights, df):
    """
    LSTM Ensemble ê²°ê³¼ + cGAN ê°€ì¤‘ì¹˜ -> ìµœì¢… ì ìˆ˜ ì‚°ì¶œ
    """
    print("\n" + "="*50)
    print("ğŸ¤– [AI ììœ¨ í•„í„°ë§] í™•ë¥  ë°ì´í„° ë¶„ì„ ë° ê²Œì„ ìƒì„±")
    print("="*50)

    # 1. í†µí•© ì ìˆ˜ ê³„ì‚°
    scores = {i: 0.0 for i in range(1, 46)}
    
    # (A) Recency Score
    recent_10 = df.iloc[-10:]
    for i, row in enumerate(recent_10.itertuples()):
        weight = i + 1
        # rowëŠ” Index, 1ë²ˆ, ... ìˆœì„œ
        nums = [row[1], row[2], row[3], row[4], row[5], row[6]]
        for n in nums:
            scores[int(n)] += weight * 0.5

    # (B) Ensemble Score (LSTM)
    for res in results:
        pred_nums = res['nums']
        weight = res['weight']
        for num in pred_nums:
            scores[int(num)] += 30.0 * weight

    # (C) cGAN Weight ì ìš© (V5 ì‹ ê·œ ê¸°ëŠ¥)
    # cGANì´ ì˜ˆì¸¡í•œ íŒ¨í„´ì— ê°€ì¤‘ì¹˜ ë¶€ì—¬ (ìµœëŒ€ 20ì  ì¶”ê°€)
    for num, weight in cgan_weights.items():
        if num in scores:
            scores[num] += weight * 20.0

    # 2. Gemini AIì—ê²Œ ìµœì¢… íŒë‹¨ ìš”ì²­
    gemini_result = get_gemini_strategy(scores)

    if gemini_result:
        print("âœ¨ Geminiê°€ ìµœì¢… ì „ëµì„ í™•ì •í–ˆìŠµë‹ˆë‹¤.")
        final_games = gemini_result.get('final_10_games', [])
        strategy_summary = gemini_result.get('strategy_summary', "ì „ëµ ìš”ì•½ ì—†ìŒ")
        elite_nums = gemini_result.get('elite_numbers', [])
        rd_insight = gemini_result.get('rd_insight', "R&D ì œì•ˆ ì—†ìŒ")

        validated_games = []
        for game in final_games:
            game = sorted([int(n) for n in game])
            if len(game) == 6:
                validated_games.append(game)

        while len(validated_games) < 10:
             if len(elite_nums) >= 6:
                 fill_game = sorted([int(n) for n in random.sample(elite_nums, 6)])
                 validated_games.append(fill_game)
             else:
                 validated_games.append([1,2,3,4,5,6])

        return validated_games[:10], len(elite_nums), strategy_summary, rd_insight

    # 3. Fallback
    print("âš ï¸ Gemini ì‚¬ìš© ë¶ˆê°€. ìì²´ Elite-20 ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)
    elite_20 = [num for num, score in sorted_scores[:20]]
    elite_20_int = [int(n) for n in elite_20]

    final_games = []
    attempts = 0
    while len(final_games) < 10 and attempts < 1000:
        attempts += 1
        weights = [scores[n] for n in elite_20_int]
        selected = []
        temp_pool = elite_20_int[:]
        temp_weights = weights[:]

        while len(selected) < 6:
             pick = random.choices(temp_pool, weights=temp_weights, k=1)[0]
             if pick not in selected:
                 selected.append(pick)

        new_game = sorted(selected)
        if new_game not in final_games:
            final_games.append(new_game)

    while len(final_games) < 10:
        final_games.append(final_games[-1] if final_games else [1,2,3,4,5,6])

    return final_games, 20, "ğŸ“‰ Gemini ì‘ë‹µ ì‹¤íŒ¨ | ìì²´ ì•Œê³ ë¦¬ì¦˜ ê°€ë™", "R&D ë°ì´í„° ì—†ìŒ"

# ==========================================
# [7] ë¦¬í¬íŠ¸ ì‘ì„±
# ==========================================
def update_report(games, elite_count, strategy_summary, rd_insight):
    """êµ¬ê¸€ ì‹œíŠ¸ì— 10ê²Œì„ ë° R&D ì •ë³´ ì‘ì„±"""
    sheet = connect_jules()
    if not sheet: return

    now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M')
    try:
        ws = sheet.worksheet("ì¶”ì²œë²ˆí˜¸")
    except:
        ws = sheet.add_worksheet(title="ì¶”ì²œë²ˆí˜¸", rows=100, cols=20)

    ws.clear()

    try:
        ws.unmerge_cells('A1:G50')
    except Exception as e:
        print(f"âš ï¸ ë³‘í•© í•´ì œ ì¤‘ ê²½ê³  (ë¬´ì‹œ ê°€ëŠ¥): {e}")

    # ë°ì´í„° ì¤€ë¹„
    data = [['' for _ in range(7)] for _ in range(50)]

    # [ì„¹ì…˜ 1] íƒ€ì´í‹€ ë° ì „ëµ
    data[0][0] = f"ğŸ’° [Hyper-Sniper V5] Tabular-Insight Edition ({now})"
    data[1][0] = "ğŸ§  ì´ë²ˆ ì£¼ AI ì „ëµ ìš”ì•½"
    data[2][0] = strategy_summary

    # [ì„¹ì…˜ 2] ê²Œì„ ë°ì´í„°
    headers = ["No.", "A", "B", "C", "D", "E", "F"]
    for j, h in enumerate(headers):
        data[5][j] = h

    for i, game in enumerate(games):
        row_idx = 6 + i
        data[row_idx][0] = f"Game {i+1}"
        for j, num in enumerate(game):
            data[row_idx][j+1] = int(num)

    # [ì„¹ì…˜ 3] R&D Insight (20í–‰ë¶€í„°)
    rd_start_row = 20
    data[rd_start_row][0] = "ğŸš€ AI Future Technology Lab (R&D Insight)"
    data[rd_start_row + 1][0] = rd_insight

    try:
        ws.update(range_name='A1', values=data)
    except Exception as e:
        print(f"âš ï¸ ë°ì´í„° ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")

    try:
        ws.merge_cells('A1:G1')
        ws.merge_cells('A2:G2')
        ws.merge_cells('A3:G5')
        ws.merge_cells('A21:G21')
        ws.merge_cells('A22:G30')
    except Exception as e:
        print(f"âš ï¸ ì…€ ë³‘í•© ì¤‘ ê²½ê³ : {e}")

    print(f"âœ… [ë¦¬í¬íŠ¸] 10ê²Œì„ ë° R&D ì œì•ˆ ì‘ì„± ì™„ë£Œ.")

# ==========================================
# [8] AI ì§„í™” ì œì•ˆ ìƒì„± (ì‹ ê·œ ì¶”ê°€)
# ==========================================
def generate_evolution_proposal(api_keys):
    """
    í˜„ì¬ ì½”ë“œë¥¼ ë¶„ì„í•˜ê³  TabNet, cGAN, PPO ë“±ì„ ì ìš©í•œ ì°¨ì„¸ëŒ€ ë²„ì „ì„ ì œì•ˆí•©ë‹ˆë‹¤.
    """
    print("\n" + "="*50)
    print("ğŸ§¬ [Evolution System] ì°¨ì„¸ëŒ€ ì½”ë“œ ì§„í™” í”„ë¡œì„¸ìŠ¤ ì‹œì‘...")

    if not api_keys:
        print("âš ï¸ API í‚¤ê°€ ì—†ì–´ ì§„í™”ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # í˜„ì¬ ì½”ë“œ ì½ê¸°
    try:
        with open(__file__, "r", encoding="utf-8") as f:
            current_code = f.read()
    except Exception as e:
        print(f"âš ï¸ í˜„ì¬ ì½”ë“œë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        return

    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"""
    ë‹¹ì‹ ì€ ì„¸ê³„ ìµœê³ ì˜ AI ì•„í‚¤í…íŠ¸ì´ì íŒŒì´ì¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ë¡œë˜ ì˜ˆì¸¡ ì‹œìŠ¤í…œ('lotto_predict.py')ì˜ ì „ì²´ ì½”ë“œë¥¼ ë¶„ì„í•˜ê³ ,
    ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í™”ì‹œí‚¨ 'ì™„ì „í•œ ì‹¤í–‰ ê°€ëŠ¥í•œ íŒŒì´ì¬ ìŠ¤í¬ë¦½íŠ¸'ë¥¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

    [ì§„í™” ëª©í‘œ]
    ì•„ë˜ ê¸°ìˆ  ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì—¬ ì‹¬ë„ ìˆê²Œ êµ¬í˜„í•˜ì‹­ì‹œì˜¤ (TabNet, cGAN ê°œì„ , PPO ê°•í™” ì¤‘ íƒ 1).
    1. **TabNet (Tabular-Insight ê°•í™”):** ê¸°ì¡´ FeatureAttentionì„ ë” ì •êµí•œ TabNet êµ¬ì¡°(Attentive Transformer, Feature Transformer)ë¡œ ì—…ê·¸ë ˆì´ë“œ.
    2. **cGAN (Data Augmentation ê³ ë„í™”):** Generator/Discriminator êµ¬ì¡°ë¥¼ ê°œì„ í•˜ê±°ë‚˜ WGAN-GP ë“±ì„ ë„ì…í•˜ì—¬ í•™ìŠµ ì•ˆì •ì„± í™•ë³´.
    3. **PPO (Reinforcement Learning):** ë‹¨ìˆœ ê°€ì¤‘ì¹˜ ì¡°ì •ì„ ë„˜ì–´, ê°•í™”í•™ìŠµ ì—ì´ì „íŠ¸ê°€ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë‚˜ ëª¨ë¸ ì„ íƒì„ ìˆ˜í–‰í•˜ë„ë¡ ê°œì„ .

    [í•„ìˆ˜ ìš”êµ¬ì‚¬í•­]
    1. **ê¸°ì¡´ ê¸°ëŠ¥ ì™„ë²½ ìœ ì§€:**
       - Apple Silicon (M5) mps ê°€ì† ì§€ì› í•„ìˆ˜ (`torch.device("mps")`).
       - êµ¬ê¸€ ì‹œíŠ¸ ì—°ë™ (gspread), 8ë‹¨ê³„ ì‹œì•¼, Gap ë¶„ì„ ë“± ê¸°ì¡´ ë¡œì§ ìœ ì§€.
       - .env í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° API í‚¤ ì²˜ë¦¬ ë¡œì§ ìœ ì§€.
    2. **ì „ì²´ ì½”ë“œ ìƒì„±:** ë¶€ë¶„ ìˆ˜ì •ì´ ì•„ë‹Œ, 'import'ë¶€í„° 'if __name__'ê¹Œì§€ ì „ì²´ ì½”ë“œë¥¼ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤.
    3. **ì œì•ˆì„œ í—¤ë” (Docstring) í•„ìˆ˜:** ì½”ë“œ ìµœìƒë‹¨ì— ì•„ë˜ í˜•ì‹ì„ ë°˜ë“œì‹œ í¬í•¨í•˜ì‹­ì‹œì˜¤.
       \"\"\"
       [Evolution Proposal]
       - Key Change: <í•µì‹¬ ë³€ê²½ ì‚¬í•­ 1ì¤„ ìš”ì•½>
       - Expected Benefit: <ê¸°ëŒ€ íš¨ê³¼ 1ì¤„ ìš”ì•½>
       - Technical Details: <ì ìš©ëœ ê¸°ìˆ ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª…>
       \"\"\"

    [ì¶œë ¥ í˜•ì‹]
    - ë§ˆí¬ë‹¤ìš´(```python ... ```) ì—†ì´ ìˆœìˆ˜ íŒŒì´ì¬ ì½”ë“œë§Œ ì¶œë ¥í•˜ê±°ë‚˜, ë§ˆí¬ë‹¤ìš´ì´ ìˆë‹¤ë©´ íŒŒì‹± ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì œê³µí•˜ì‹­ì‹œì˜¤.

    [í˜„ì¬ ì½”ë“œ ì»¨í…ìŠ¤íŠ¸]
    {current_code}
    """

    models = ["gemini-3-flash-preview", "gemini-2.0-flash-exp", "gemini-1.5-pro"]
    generated_code = None
    selected_model = ""

    for model_name in models:
        print(f"ğŸ” [{model_name}] ì§„í™” ëª¨ë¸ ì‹œë„ ì¤‘...")
        for key in api_keys:
            try:
                client = genai.Client(api_key=key)
                response = client.models.generate_content(
                    model=model_name,
                    contents=prompt
                )

                text_content = response.text
                if "```python" in text_content:
                    generated_code = text_content.split("```python")[1].split("```")[0].strip()
                elif "```" in text_content:
                    generated_code = text_content.split("```")[1].split("```")[0].strip()
                else:
                    generated_code = text_content.strip()

                if generated_code and "import" in generated_code and "if __name__" in generated_code:
                    selected_model = model_name
                    break
                else:
                    print(f"âš ï¸ ìƒì„±ëœ ì½”ë“œ ê²€ì¦ ì‹¤íŒ¨ ({model_name}): import ë˜ëŠ” if __name__ êµ¬ë¬¸ ëˆ„ë½")
            except Exception as e:
                print(f"âš ï¸ ì—ëŸ¬ ë°œìƒ ({model_name}): {e}")
                continue
        if generated_code:
            break

    if not generated_code:
        print("âš ï¸ ì§„í™”ëœ ì½”ë“œë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return

    # ì €ì¥
    os.makedirs("proposals", exist_ok=True)
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"proposals/{timestamp}_proposal.py"

    with open(filename, "w", encoding="utf-8") as f:
        f.write(generated_code)

    print(f"âœ¨ [ì§„í™” ì™„ë£Œ] ìƒˆë¡œìš´ ì œì•ˆì„œê°€ ë„ì°©í–ˆìŠµë‹ˆë‹¤: {filename} (Model: {selected_model})")
    print("="*50)


# ==========================================
# [9] ë©”ì¸ ì‹¤í–‰ë¶€
# ==========================================
if __name__ == "__main__":
    df = load_data()
    if df is not None:
        # í•™ìŠµ ë° ì˜ˆì¸¡ (LSTM Ensemble + cGAN)
        results, cgan_weights = run_pipeline(df)

        # AI ë¶„ì„ ë° ê²Œì„ ìƒì„±
        final_games, elite_cnt, strategy_summary, rd_insight = analyze_and_generate(results, cgan_weights, df)

        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ² ìµœì¢… ìƒì„±ëœ 10ê²Œì„ (Hyper-Sniper V5):")
        print(f"ğŸ“ ì „ëµ ìš”ì•½: {strategy_summary}")
        print(f"ğŸ’¡ R&D Insight: {rd_insight[:50]}...\n")
        for idx, game in enumerate(final_games):
            print(f"  Game {idx+1}: {game}")

        # ë¦¬í¬íŠ¸ ì „ì†¡
        update_report(final_games, elite_cnt, strategy_summary, rd_insight)

        # [NEW] ì§„í™” í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
        generate_evolution_proposal(API_KEYS)

    print("\n" + "="*50)
    print("ğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("="*50)
