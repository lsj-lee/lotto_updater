import os
import time
import gc
import random
import json
import datetime
import re
import multiprocessing
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from googleapiclient.discovery import build
from dotenv import load_dotenv
import requests
import joblib
import sys

# [ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸] Google GenAI SDK (v1.0+)
try:
    from google import genai
    from google.genai import types
except ImportError:
    print("âŒ Critical Dependency Missing: 'google-genai'")
    print("ğŸ’¡ Run: pip install google-genai")
    sys.exit(1)

from bs4 import BeautifulSoup

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ==========================================
# âš™ï¸ [Configuration] ì‚¬ìš©ì ì„¤ì •
# ==========================================
# âš ï¸ [ì¤‘ìš”] ìŠ¤í”„ë ˆë“œì‹œíŠ¸ IDë¥¼ ì—¬ê¸°ì— ì…ë ¥í•˜ê±°ë‚˜ .env íŒŒì¼ì— 'SPREADSHEET_ID'ë¡œ ì„¤ì •í•˜ì„¸ìš”.
# ë¸Œë¼ìš°ì € ì£¼ì†Œì°½ì˜ https://docs.google.com/spreadsheets/d/THIS_LONG_STRING/edit ì—ì„œ ë³µì‚¬
SPREADSHEET_ID = os.getenv("SPREADSHEET_ID", "ENTER_YOUR_SPREADSHEET_ID_HERE")

CREDS_FILE = 'creds_lotto.json'
SHEET_NAME = 'ë¡œë˜ max'  # (ë°±ì—…ìš© ì´ë¦„)
REC_SHEET_NAME = 'ì¶”ì²œë²ˆí˜¸'
STATE_FILE = 'hybrid_sniper_v5_state.pth'

# [M5 Hardware Protection]
# Apple Silicon (MPS) ê°€ì† ì‚¬ìš©, ì½”ì–´ ê³¼ì—´ ë°©ì§€
TOTAL_CORES = multiprocessing.cpu_count()
USED_CORES = 6
torch.set_num_threads(USED_CORES)

if torch.backends.mps.is_available():
    DEVICE = torch.device("mps")
    print(f"ğŸš€ [System] M5 Neural Engine Activated (MPS/Metal). Cores: {USED_CORES}")
else:
    DEVICE = torch.device("cpu")
    print("âš ï¸ [System] Running on CPU (MPS not found).")

# [Network] ìœ„ì¥ í—¤ë”
REAL_BROWSER_HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    "Referer": "https://www.naver.com/"
}

# ==========================================
# ğŸ§  [Phase 2] The Brain: NDA & Hybrid Network
# ==========================================

class NDA_FeatureEngine:
    """
    [NDA] ë‹¤ì°¨ì› ë°ì´í„° ë¶„ì„ ì—”ì§„
    - ì‹œê³„ì—´(Time-Series) + í†µê³„ì (Statistical) + ê´€ê³„ì (Relational) ë°ì´í„° ìƒì„±
    """
    @staticmethod
    def calculate_derived_features(numbers_list):
        """ë…¼ë¦¬ íŠ¹ì„± ë ˆì´ì–´: í•©ê³„, í™€ì§ë¹„, ê³ ì €ë¹„, ACì§€ìˆ˜"""
        features = []
        for nums in numbers_list:
            # 1. Sum (ì´í•©) -> ì •ê·œí™” (ë³´í†µ 100~200 ì‚¬ì´)
            s = sum(nums)
            # 2. Odd/Even (í™€ì§) -> í™€ìˆ˜ ê°œìˆ˜ (0~6)
            odd = sum(1 for n in nums if n % 2 != 0)
            # 3. High/Low (ê³ ì €: 23ì´ìƒ) -> ê³ ë²ˆí˜¸ ê°œìˆ˜ (0~6)
            high = sum(1 for n in nums if n >= 23)
            # 4. AC Index (ë³µì¡ë„)
            diffs = set()
            for i in range(len(nums)):
                for j in range(i+1, len(nums)):
                    diffs.add(nums[j] - nums[i])
            ac = len(diffs) - (6 - 1)

            features.append([s/255.0, odd/6.0, high/6.0, ac/10.0])
        return np.array(features)

    @staticmethod
    def create_multimodal_dataset(data, lookback=10):
        """
        ë°ì´í„°ë¥¼ 3ê°€ì§€ ë¸Œëœì¹˜(Branch A, B, C) ì…ë ¥ í˜•íƒœë¡œ ë³€í™˜
        """
        X_seq, X_stat, y = [], [], []
        if len(data) <= lookback: return None, None, None

        # ê¸°ë³¸ ìˆ«ì ë°ì´í„° (1~45)
        raw_nums = np.array(data)
        # íŒŒìƒ íŠ¹ì„± ë°ì´í„°
        derived = NDA_FeatureEngine.calculate_derived_features(data)

        for i in range(lookback, len(data)):
            # Branch A input: ì‹œê³„ì—´ (Lookback ì£¼ì°¨ì˜ ë²ˆí˜¸ íë¦„)
            # (Batch, Lookback, 6)
            seq = raw_nums[i-lookback:i]
            # ì •ê·œí™” (1~45 -> 0~1)
            X_seq.append(seq / 45.0)

            # Branch B input: í†µê³„ì  íŠ¹ì„± (ì§ì „ íšŒì°¨ì˜ íŒŒìƒ ë³€ìˆ˜)
            # (Batch, 4)
            stat = derived[i-1]
            X_stat.append(stat)

            # Target: ì´ë²ˆ íšŒì°¨ ë²ˆí˜¸ (Multi-hot encoding for Classification)
            target = np.zeros(45)
            for n in raw_nums[i]:
                target[n-1] = 1
            y.append(target)

        return (
            torch.tensor(np.array(X_seq), dtype=torch.float32).to(DEVICE),
            torch.tensor(np.array(X_stat), dtype=torch.float32).to(DEVICE),
            torch.tensor(np.array(y), dtype=torch.float32).to(DEVICE)
        )

class CreativeConnectionModel(nn.Module):
    """
    [CC] ë©€í‹°-í—¤ë“œ í•˜ì´ë¸Œë¦¬ë“œ ì‹ ê²½ë§ (Phase 2 Core)
    - Branch A (LSTM): ì‹œê³„ì—´ íŒ¨í„´ í•™ìŠµ
    - Branch B (Dense): í†µê³„ì /ë…¼ë¦¬ì  íŠ¹ì„± í•™ìŠµ
    - Decision Head: í†µí•© ì¶”ë¡ 
    """
    def __init__(self):
        super(CreativeConnectionModel, self).__init__()

        # Branch A: Time-Series (LSTM)
        # Input: (Batch, Lookback, 6)
        self.lstm = nn.LSTM(input_size=6, hidden_size=128, num_layers=2, batch_first=True, dropout=0.2)
        self.ln_a = nn.LayerNorm(128)

        # Branch B: Statistical Features (TabNet-style Dense)
        # Input: (Batch, 4)
        self.stat_net = nn.Sequential(
            nn.Linear(4, 32),
            nn.ReLU(),
            nn.Linear(32, 32),
            nn.BatchNorm1d(32)
        )

        # Decision Head (Fusion)
        # LSTM(128) + Stat(32) = 160
        self.head = nn.Sequential(
            nn.Linear(128 + 32, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 45), # 45ê°œ ë²ˆí˜¸ì— ëŒ€í•œ Logits
            nn.Sigmoid()        # í™•ë¥  (0~1)
        )

    def forward(self, x_seq, x_stat):
        # Branch A
        # LSTM output: (Batch, Lookback, Hidden)
        out_seq, _ = self.lstm(x_seq)
        # Take the last time step's hidden state
        out_seq = self.ln_a(out_seq[:, -1, :])

        # Branch B
        out_stat = self.stat_net(x_stat)

        # Fusion
        combined = torch.cat([out_seq, out_stat], dim=1)
        output = self.head(combined)
        return output

# ==========================================
# ğŸ›°ï¸ [System] Scout & Interface
# ==========================================

def get_verified_model(api_key):
    """Scout: Finds the best available Gemini model"""
    print("ğŸ›°ï¸ [Scout] Scanning for Gemini Models...")
    if not api_key: return None

    candidates = ["gemini-2.0-flash-exp", "gemini-1.5-pro", "gemini-1.5-flash"]
    best_model = None

    for model in candidates:
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"
        try:
            # Simple Ping
            payload = {"contents": [{"parts": [{"text": "Ping"}]}]}
            resp = requests.post(url, json=payload, timeout=3)
            if resp.status_code == 200:
                print(f"   âœ… Active: {model}")
                return model # Return first active one
        except: continue

    return "gemini-1.5-flash" # Fallback

class LottoOrchestrator:
    def __init__(self):
        self.creds_file = CREDS_FILE
        self.gc, self.docs = self._auth()

        api_key = os.getenv("GEMINI_API_KEY")
        self.model_name = get_verified_model(api_key)
        try:
            self.client = genai.Client(api_key=api_key)
        except:
            self.client = None
            print("âš ï¸ GenAI Client Init Failed (Manual Mode)")

    def _auth(self):
        # [Phase 3] Scope Update for Drive/Docs/Sheets
        scope = [
            "https://spreadsheets.google.com/feeds",
            "https://www.googleapis.com/auth/drive.file",
            "https://www.googleapis.com/auth/documents",
            "https://www.googleapis.com/auth/spreadsheets"
        ]
        if not os.path.exists(self.creds_file):
             print(f"âŒ Credential file '{self.creds_file}' not found.")
             sys.exit(1)

        creds = ServiceAccountCredentials.from_json_keyfile_name(self.creds_file, scope)
        gc = gspread.authorize(creds)
        try:
            docs = build('docs', 'v1', credentials=creds)
        except:
            docs = None
        return gc, docs

    def get_sheet(self):
        """Open sheet by ID (Priority) or Name (Fallback)"""
        try:
            if SPREADSHEET_ID and "ENTER" not in SPREADSHEET_ID:
                return self.gc.open_by_key(SPREADSHEET_ID)
            else:
                print(f"âš ï¸ Warning: SPREADSHEET_ID not set. Trying name '{SHEET_NAME}'...")
                return self.gc.open(SHEET_NAME)
        except Exception as e:
            print(f"âŒ Spreadsheet Connection Failed: {e}")
            print("ğŸ’¡ Solution: Set 'SPREADSHEET_ID' in the code to your file's ID.")
            sys.exit(1)

    # --- [Phase 1] Intelligent Sync ---
    def sync_data(self):
        print("\nğŸ”„ [Phase 1] Executing Intelligent Naver Sync...")
        try:
            sh = self.get_sheet()
            ws = sh.get_worksheet(0)

            # Local Last Round
            try:
                col1 = ws.col_values(1)
                if len(col1) > 1:
                    local_last = int(str(col1[-1]).replace(',', '').replace('íšŒ', ''))
                else:
                    local_last = 0
            except: local_last = 0

            # Portal Last Round
            portal_last = self._get_naver_latest_round()
            print(f"   ğŸ“Š Status: Local({local_last}) vs Portal({portal_last})")

            if portal_last > local_last:
                for r in range(local_last + 1, portal_last + 1):
                    data = self._scrape_round_detail(r)
                    if data:
                        row = [
                            data['drwNo'], data['drwNoDate'],
                            data['drwtNo1'], data['drwtNo2'], data['drwtNo3'],
                            data['drwtNo4'], data['drwtNo5'], data['drwtNo6'],
                            data['bnusNo'], data.get('firstPrzwnerCo',0), data.get('firstAccumamnt',0), ""
                        ]
                        ws.append_row(row)
                        print(f"   âœ… Synced Round {r}")
                        time.sleep(2)
            else:
                print("   âœ… Already Up-to-Date.")

        except Exception as e:
            print(f"âŒ Sync Error: {e}")

    def _get_naver_latest_round(self):
        url = "https://search.naver.com/search.naver?query=ë¡œë˜"
        try:
            res = requests.get(url, headers=REAL_BROWSER_HEADERS, timeout=5)
            # Regex for "1234íšŒì°¨"
            m = re.search(r'(\d+)íšŒì°¨', res.text)
            if m: return int(m.group(1))
            return 0
        except: return 0

    def _scrape_round_detail(self, round_no):
        """Naver Search -> Gemini Parse -> Regex Fallback"""
        url = f"https://search.naver.com/search.naver?query=ë¡œë˜+{round_no}íšŒ+ë‹¹ì²¨ë²ˆí˜¸"
        text = ""
        try:
            res = requests.get(url, headers=REAL_BROWSER_HEADERS, timeout=5)
            soup = BeautifulSoup(res.text, 'html.parser')
            text = soup.get_text()[:5000]

            # 1. AI Parsing
            if self.client:
                prompt = f"Extract Lotto {round_no} numbers from text. JSON format: {{'drwNo': {round_no}, 'drwNoDate': 'YYYY-MM-DD', 'drwtNo1':.., 'bnusNo':.., 'firstPrzwnerCo': 0, 'firstAccumamnt': 0}}. Text: {text}"
                try:
                    resp = self.client.models.generate_content(model=self.model_name, contents=prompt)
                    js_str = resp.text.replace('```json','').replace('```','')
                    js = json.loads(js_str)
                    if js.get('drwtNo1') and js['drwtNo1'] > 0: return js
                except: pass

            # 2. Regex Fallback
            print(f"   âš ï¸ AI Parsing Failed for {round_no}. Engaging Regex...")
            # Pattern: Try to find sequence of 6 numbers + 1 bonus
            # This is a basic fallback for '1, 2, 3, 4, 5, 6 + 7' patterns often found in text
            nums = re.findall(r'\b(\d{1,2})\b', text)
            nums = [int(n) for n in nums if 1 <= int(n) <= 45]

            # íœ´ë¦¬ìŠ¤í‹±: 1~45 ì‚¬ì´ ìˆ«ìê°€ 7ê°œ ì´ìƒ ì—°ì†ìœ¼ë¡œ ë‚˜ì˜¤ê±°ë‚˜ ê·¼ì²˜ì— ëª¨ì—¬ìˆìœ¼ë©´ ë¡œë˜ ë²ˆí˜¸ë¡œ ì¶”ì •
            # ì •í™•ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì‹¤íŒ¨ ì²˜ë¦¬í•˜ê±°ë‚˜ ì•„ì£¼ ì—„ê²©í•˜ê²Œ ì²´í¬
            # ì—¬ê¸°ì„œëŠ” ì•ˆì „ì„ ìœ„í•´ None ë°˜í™˜ (ì˜ëª»ëœ ë°ì´í„° ì…ë ¥ ë°©ì§€)
            return None

        except: return None

    # --- [Phase 2] Training ---
    def train_brain(self):
        print("\nğŸ§  [Phase 2] Training Hybrid Neural Network (M5/MPS)...")
        sh = self.get_sheet()
        ws = sh.get_worksheet(0)
        rows = ws.get_all_values()[1:]

        data = []
        for r in rows:
            try:
                # ë²ˆí˜¸ê°€ ìˆëŠ” ì—´ë§Œ ì¶”ì¶œ (ë³´í†µ C~Hì—´, ì¦‰ ì¸ë±ìŠ¤ 2~7 + ë³´ë„ˆìŠ¤ 8)
                # ì—¬ê¸°ì„œëŠ” 1~6ë²ˆ ê³µë§Œ ì‚¬ìš© (ì¸ë±ìŠ¤ 2~7)
                nums = [int(x.replace(',','')) for x in r[2:8]]
                data.append(nums)
            except: pass

        if len(data) < 50:
            print("âŒ Not enough data to train.")
            return None, None

        # Prepare Data
        X_seq, X_stat, y = NDA_FeatureEngine.create_multimodal_dataset(data, lookback=10)
        if X_seq is None: return None, None

        # Model Setup
        model = CreativeConnectionModel().to(DEVICE)
        opt = optim.Adam(model.parameters(), lr=0.001)
        crit = nn.BCELoss()

        # Training Loop (with Progress)
        model.train()
        epochs = 100
        print(f"   ğŸ”¥ Ignite: Training {epochs} epochs on {DEVICE}...")

        for e in range(epochs):
            opt.zero_grad()
            out = model(X_seq, X_stat)
            loss = crit(out, y)
            loss.backward()
            opt.step()

            if (e+1) % 20 == 0:
                print(f"   Epoch {e+1}/{epochs} | Loss: {loss.item():.4f}")

        # Save Weights (IW)
        torch.save(model.state_dict(), STATE_FILE)
        print("   âœ… Brain Saved.")

        return model, data

    # --- [Phase 3] Prediction & Report ---
    def generate_report(self, model, data):
        if not model: return
        print("\nğŸ“ [Phase 3] Generative Strategy Reporting...")
        model.eval()

        # Predict Next
        # Input for prediction is the LAST 10 weeks of data
        input_raw = data[-10:]
        input_seq = torch.tensor(np.array(input_raw) / 45.0, dtype=torch.float32).unsqueeze(0).to(DEVICE)

        # Stat input is based on the VERY LAST week
        last_stat = NDA_FeatureEngine.calculate_derived_features([data[-1]])
        input_stat = torch.tensor(last_stat, dtype=torch.float32).to(DEVICE)

        with torch.no_grad():
            probs = model(input_seq, input_stat).cpu().numpy()[0]

        # Select Top 15
        top_indices = probs.argsort()[::-1][:15]
        top_nums = [int(n+1) for n in top_indices] # 1-based, int conversion
        print(f"   ğŸ¯ Target Lock: {top_nums}")

        # Generate 10 Games (Intelligent Combination)
        games = []
        for _ in range(10):
            # Weighted random choice from top 15
            # Or just simple random for variety
            g = sorted(random.sample(top_nums, 6))
            games.append(g)

        # Write to Docs & Sheet
        self._write_docs(games, top_nums)
        self._write_sheet(games)

    def _write_docs(self, games, candidates):
        if not self.docs: return
        print("   ğŸ“„ Writing to Google Docs...")

        doc_title = f"Sniper V5 Report - {datetime.date.today()}"
        try:
            body = {'title': doc_title}
            doc = self.docs.documents().create(body=body).execute()
            doc_id = doc['documentId']

            content = f"[Sniper V5 Strategic Report]\nDate: {datetime.date.today()}\n"
            content += f"Target Candidates (Top 15): {candidates}\n\n"
            content += "[Tactical Combinations]\n"
            for i, g in enumerate(games):
                content += f"Scenario {i+1}: {g}\n"
            content += "\n[End of Report]"

            reqs = [{'insertText': {'location': {'index': 1}, 'text': content}}]
            self.docs.documents().batchUpdate(documentId=doc_id, body={'requests': reqs}).execute()
            print(f"   âœ… Report URL: https://docs.google.com/document/d/{doc_id}")
        except Exception as e:
            print(f"   âš ï¸ Docs Error: {e}")

    def _write_sheet(self, games):
        try:
            sh = self.get_sheet()
            # Try to get or create recommendation sheet
            try:
                ws = sh.worksheet(REC_SHEET_NAME)
            except:
                ws = sh.add_worksheet(title=REC_SHEET_NAME, rows=100, cols=20)

            ws.clear()
            ws.update(range_name='A1', values=[['ğŸ† Sniper V5 Generated Games']])

            rows = []
            for i, g in enumerate(games):
                rows.append([f"Scenario {i+1}"] + g)

            ws.update(range_name='A3', values=rows)
            print("   âœ… Google Sheet Updated.")
        except Exception as e:
            print(f"âš ï¸ Sheet Write Error: {e}")

# --- Main Execution ---
if __name__ == "__main__":
    app = LottoOrchestrator()

    # Check for Scheduled Mode (GitHub Actions / Cron)
    if "--scheduled" in sys.argv:
        day = datetime.datetime.now().strftime("%a")
        print(f"ğŸ—“ï¸ Scheduled Mode: Today is {day}")

        if day == "Sun":
            # Sunday: Only Sync Data
            app.sync_data()
        elif day == "Mon":
            # Monday: Weekly Analysis (Training)
            app.train_brain()
        elif day == "Wed":
            # Wednesday: Final Prediction & Report
            # (Need to train first to get model)
            model, data = app.train_brain()
            if model and data:
                app.generate_report(model, data)
        else:
            print("ğŸ’¤ No scheduled mission for today.")

    else:
        # Default: Full Cycle (Manual Execution)
        print("ğŸš€ Manual Mode: Executing Full Strategy...")

        # 1. Sync
        app.sync_data()

        # 2. Train
        model, data = app.train_brain()

        # 3. Report
        if model and data:
            app.generate_report(model, data)

    print("\nâœ… Mission Accomplished.")
