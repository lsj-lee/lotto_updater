# -*- coding: utf-8 -*-
import os
import sys
import difflib
import ast
import datetime
import json
from dotenv import load_dotenv

try:
    from google import genai
except ImportError:
    print("âŒ 'google-genai' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. (pip install google-genai)")
    sys.exit(1)

load_dotenv()

class EvolutionManager:
    """
    ğŸ§¬ [Phase 4] ììœ¨ ì§„í™” ê´€ë¦¬ì (Self-Evolution Manager)
    - ì½”ë“œ ìê°€ ìˆ˜ì • (Code Evolution)
    - í”„ë¡¬í”„íŠ¸ ìê°€ ê°œì„  (Meta-Prompting)
    """
    def __init__(self):
        self.api_key = os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            print("âš ï¸ GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            self.client = None
        else:
            try:
                self.client = genai.Client(api_key=self.api_key)
                print("ğŸ§¬ [Evolution] Gemini AI ì—°ê²° ì„±ê³µ.")
            except Exception as e:
                print(f"âŒ Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.client = None

    # ------------------------------------------------------------------
    # 1. Code Evolution (ê¸°ì¡´ ê¸°ëŠ¥)
    # ------------------------------------------------------------------
    def analyze_code(self, file_path='lotto_predict.py'):
        if not self.client: return None
        print(f"ğŸ” [Code Evolution] {file_path} ë¶„ì„ ì¤‘...")
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                current_code = f.read()
        except FileNotFoundError:
            return None

        prompt = f"""
        ë‹¹ì‹ ì€ íŒŒì´ì¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ ì„±ëŠ¥, ê°€ë…ì„±, ì•ˆì •ì„±ì„ ë†’ì¼ ìˆ˜ ìˆëŠ” ê°œì„ ì•ˆì„ 1ê°€ì§€ë§Œ ì œì•ˆí•˜ì„¸ìš”.
        ë°˜ë“œì‹œ ì „ì²´ ì½”ë“œë¥¼ ìˆ˜ì •ëœ ìƒíƒœë¡œ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤.

        [í˜„ì¬ ì½”ë“œ]
        {current_code}
        """
        try:
            response = self.client.models.generate_content(model='gemini-2.5-flash', contents=prompt)
            new_code = response.text.strip()
            if new_code.startswith("```python"): new_code = new_code[9:]
            if new_code.startswith("```"): new_code = new_code[3:]
            if new_code.endswith("```"): new_code = new_code[:-3]
            return new_code.strip()
        except: return None

    def safe_apply_update(self, file_path, new_code):
        if not new_code: return {"success": False, "detail": "No code generated"}
        try:
            ast.parse(new_code)
        except SyntaxError as e:
            return {"success": False, "detail": f"Syntax Error: {e}"}

        print("\nğŸ“ [Code Diff] ë³€ê²½ ì‚¬í•­ ë¯¸ë¦¬ë³´ê¸°:")
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                original_lines = f.readlines()
        except: original_lines = []

        new_lines = new_code.splitlines(keepends=True)
        diff = difflib.unified_diff(original_lines, new_lines, fromfile='Original', tofile='Proposed')
        diff_text = "".join(diff)

        if not diff_text: return {"success": False, "detail": "No changes"}
        print(diff_text[:1000] + "...")

        if not sys.stdin.isatty():
            return {"success": False, "detail": "Background mode (Skipped)"}

        choice = input("ğŸ‘‰ ì½”ë“œ ë³€ê²½ì„ ìŠ¹ì¸í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (Y/N): ").strip().upper()
        if choice == 'Y':
            backup_path = file_path + ".bak"
            try:
                with open(backup_path, 'w', encoding='utf-8') as f: f.writelines(original_lines)
                with open(file_path, 'w', encoding='utf-8') as f: f.write(new_code)
                return {"success": True, "detail": "Applied updates"}
            except Exception as e:
                return {"success": False, "detail": f"Write Error: {e}"}
        return {"success": False, "detail": "User cancelled"}

    # ------------------------------------------------------------------
    # 2. Meta-Prompting (ì‹ ê·œ ê¸°ëŠ¥)
    # ------------------------------------------------------------------
    def evolve_prompt(self, current_prompt, recent_stats):
        """
        [Meta-Prompting] ì„±ê³¼ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„ í”„ë¡¬í”„íŠ¸ë¥¼ ìŠ¤ìŠ¤ë¡œ ê°œì„ í•©ë‹ˆë‹¤.
        """
        if not self.client:
            return {"success": False, "detail": "No AI Client"}

        avg_hit = np.mean(recent_stats) if recent_stats else 0.0
        print(f"ğŸ§¬ [Prompt Evolution] ìµœê·¼ í‰ê·  ì ì¤‘ë¥ : {avg_hit:.2f}ê°œ")

        meta_prompt = f"""
        ë‹¹ì‹ ì€ 'í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ AI'ì…ë‹ˆë‹¤.
        ìš°ë¦¬ëŠ” ë¡œë˜ ë²ˆí˜¸ ì˜ˆì¸¡ ì‹œìŠ¤í…œì„ ìš´ì˜ ì¤‘ì´ë©°, í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ 'ë¶„ì„ í”„ë¡¬í”„íŠ¸'ì˜ ì„±ëŠ¥ì„ ê°œì„ í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤.

        [í˜„ì¬ í”„ë¡¬í”„íŠ¸]
        "{current_prompt}"

        [ìµœê·¼ ì„±ê³¼]
        - ìµœê·¼ 5ì£¼ í‰ê·  ì ì¤‘ ê°œìˆ˜: {avg_hit:.2f}ê°œ (ëª©í‘œ: 3.0ê°œ ì´ìƒ)

        [ì„ë¬´]
        ìœ„ ì„±ê³¼ë¥¼ ë¶„ì„í•˜ì—¬, ë” ë†’ì€ ì ì¤‘ë¥ ì„ ë‚¼ ìˆ˜ ìˆë„ë¡ 'í˜„ì¬ í”„ë¡¬í”„íŠ¸'ë¥¼ ìˆ˜ì •/ë³´ì™„í•´ ì£¼ì„¸ìš”.
        ì˜ˆë¥¼ ë“¤ì–´, "ë²ˆí˜¸ì˜ ë¶„í¬ë¥¼ ë” ë„“ê²Œ í¼ëœ¨ë ¤ë¼", "ìµœê·¼ 10íšŒì°¨ì˜ ë¯¸ì¶œí˜„ ë²ˆí˜¸ë¥¼ ê³ ë ¤í•˜ë¼" ë“±ì˜ êµ¬ì²´ì  ì§€ì‹œë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

        [ì¶œë ¥ í˜•ì‹]
        ì˜¤ì§ ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ ë‚´ìš©ë§Œ ì¶œë ¥í•˜ì„¸ìš”. (ì„¤ëª…ì´ë‚˜ ë§ˆí¬ë‹¤ìš´ ì—†ì´)
        """

        try:
            response = self.client.models.generate_content(
                model='gemini-2.5-flash',
                contents=meta_prompt
            )
            new_prompt = response.text.strip()
            return {"success": True, "new_prompt": new_prompt}
        except Exception as e:
            return {"success": False, "detail": f"Meta-Prompting Failed: {e}"}

    # ------------------------------------------------------------------
    # Main Entry
    # ------------------------------------------------------------------
    def execute_evolution_cycle(self, target_file='lotto_predict.py', state_manager=None):
        """
        ì „ì²´ ì§„í™” ì‚¬ì´í´:
        1. ì½”ë“œ ìµœì í™” ì œì•ˆ (Interactive)
        2. í”„ë¡¬í”„íŠ¸ ì§„í™” (Background/Automatic)
        """
        results = {}

        # 1. ì½”ë“œ ì§„í™” (ì‚¬ìš©ì ê°œì… í•„ìš”)
        if sys.stdin.isatty():
            code_res = self.analyze_code(target_file)
            if code_res:
                results['code'] = self.safe_apply_update(target_file, code_res)

        # 2. í”„ë¡¬í”„íŠ¸ ì§„í™” (ìë™ ìˆ˜í–‰)
        if state_manager:
            current_state = state_manager.state
            current_prompt = current_state.get("active_strategy_prompt", {}).get("content", "")
            recent_stats = current_state.get("recent_hit_rates", [])

            # ì„±ê³¼ ë°ì´í„°ê°€ ì¶©ë¶„í•  ë•Œë§Œ ì§„í™” ì‹œë„
            if len(recent_stats) > 0:
                print("ğŸ§¬ [Meta-Prompting] í”„ë¡¬í”„íŠ¸ ìê°€ ê°œì„  ì‹œë„ ì¤‘...")
                prompt_res = self.evolve_prompt(current_prompt, recent_stats)

                if prompt_res.get("success"):
                    new_version = f"v{datetime.datetime.now().strftime('%m%d-%H%M')}"
                    state_manager.update_strategy_prompt(prompt_res['new_prompt'], new_version)
                    results['prompt'] = {"success": True, "version": new_version}
                    print(f"âœ¨ ì „ëµ í”„ë¡¬í”„íŠ¸ê°€ '{new_version}'ìœ¼ë¡œ ì§„í™”í–ˆìŠµë‹ˆë‹¤.")
                else:
                    results['prompt'] = prompt_res
            else:
                print("â„¹ï¸ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ì§„í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

        return results

if __name__ == "__main__":
    manager = EvolutionManager()
    # í…ŒìŠ¤íŠ¸ìš© ëª¨ì˜ ê°ì²´
    class MockState:
        state = {"active_strategy_prompt": {"content": "Test Prompt"}, "recent_hit_rates": [2.5, 3.0]}
        def update_strategy_prompt(self, p, v): print(f"Updated: {v}")

    manager.execute_evolution_cycle(state_manager=MockState())
